{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Image Processing Steps - License Plate Detection\n",
        "\n",
        "Notebook n√†y tr√¨nh b√†y c√°c b∆∞·ªõc x·ª≠ l√Ω ·∫£nh ƒë·ªÉ ph√°t hi·ªán bi·ªÉn s·ªë xe.\n",
        "\n",
        "## üöÄ H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng tr√™n Google Colab:\n",
        "\n",
        "1. Ch·∫°y c√°c cell theo th·ª© t·ª± t·ª´ tr√™n xu·ªëng\n",
        "2. ·ªû cell \"Upload ·∫£nh\", ch·ªçn file ·∫£nh bi·ªÉn s·ªë ƒë·ªÉ upload\n",
        "3. C√°c b∆∞·ªõc x·ª≠ l√Ω s·∫Ω t·ª± ƒë·ªông hi·ªÉn th·ªã k·∫øt qu·∫£\n",
        "\n",
        "## üìã C√°c b∆∞·ªõc x·ª≠ l√Ω:\n",
        "\n",
        "1. **Resize ·∫£nh** v·ªÅ k√≠ch th∆∞·ªõc chu·∫©n (1920x1080)\n",
        "2. **Chuy·ªÉn ƒë·ªïi sang Grayscale** (HSV Value channel)\n",
        "3. **TƒÉng ƒë·ªô t∆∞∆°ng ph·∫£n** (Top Hat + Black Hat morphology)\n",
        "4. **L√†m m·ªãn ·∫£nh** (Gaussian Blur)\n",
        "5. **Nh·ªã ph√¢n h√≥a** (Adaptive Threshold)\n",
        "6. **Ph√°t hi·ªán c·∫°nh** (Canny Edge Detection)\n",
        "7. **Dilation** (n·ªëi c√°c c·∫°nh b·ªã ƒë·ª©t ƒëo·∫°n)\n",
        "8. **T√¨m contour** v√† ph√°t hi·ªán bi·ªÉn s·ªë\n",
        "\n",
        "**L∆∞u √Ω:** Notebook n√†y ch·ªâ x·ª≠ l√Ω ·∫£nh v√† ph√°t hi·ªán bi·ªÉn s·ªë, kh√¥ng bao g·ªìm ph·∫ßn nh·∫≠n d·∫°ng k√Ω t·ª±.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Ki·ªÉm tra m√¥i tr∆∞·ªùng\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# T·ª± ƒë·ªông ph√°t hi·ªán m√¥i tr∆∞·ªùng Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"üåê ƒêang ch·∫°y tr√™n Google Colab\")\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"üíª ƒêang ch·∫°y tr√™n m√°y local (Jupyter)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Import Libraries v√† ƒë·ªãnh nghƒ©a c√°c class x·ª≠ l√Ω ·∫£nh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (15, 10)\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "class ImagePreprocessor:\n",
        "    GAUSSIAN_SMOOTH_FILTER_SIZE = (5, 5)\n",
        "    ADAPTIVE_THRESH_BLOCK_SIZE = 19\n",
        "    ADAPTIVE_THRESH_WEIGHT = 9\n",
        "    MORPHOLOGY_ITERATIONS = 10\n",
        "    MORPHOLOGY_KERNEL_SIZE = (3, 3)\n",
        "    \n",
        "    def extract_value(self, img_original):\n",
        "        img_hsv = cv2.cvtColor(img_original, cv2.COLOR_BGR2HSV)\n",
        "        _, _, img_value = cv2.split(img_hsv)\n",
        "        return img_value\n",
        "    \n",
        "    def maximize_contrast(self, img_grayscale):\n",
        "        structuring_element = cv2.getStructuringElement(\n",
        "            cv2.MORPH_RECT, \n",
        "            self.MORPHOLOGY_KERNEL_SIZE\n",
        "        )\n",
        "        \n",
        "        img_top_hat = cv2.morphologyEx(\n",
        "            img_grayscale, \n",
        "            cv2.MORPH_TOPHAT, \n",
        "            structuring_element, \n",
        "            iterations=self.MORPHOLOGY_ITERATIONS\n",
        "        )\n",
        "        \n",
        "        img_black_hat = cv2.morphologyEx(\n",
        "            img_grayscale, \n",
        "            cv2.MORPH_BLACKHAT, \n",
        "            structuring_element, \n",
        "            iterations=self.MORPHOLOGY_ITERATIONS\n",
        "        )\n",
        "        \n",
        "        img_plus_top_hat = cv2.add(img_grayscale, img_top_hat)\n",
        "        img_enhanced = cv2.subtract(img_plus_top_hat, img_black_hat)\n",
        "        \n",
        "        return img_enhanced\n",
        "\n",
        "\n",
        "class PlateDetector:\n",
        "    CANNY_THRESHOLD_LOW = 250\n",
        "    CANNY_THRESHOLD_HIGH = 255\n",
        "    DILATION_KERNEL_SIZE = (3, 3)\n",
        "    DILATION_ITERATIONS = 1\n",
        "    APPROX_POLY_EPSILON_FACTOR = 0.06\n",
        "    MAX_CONTOURS = 10\n",
        "    TARGET_SIZE = (1920, 1080)\n",
        "    \n",
        "    def resize_image(self, img):\n",
        "        return cv2.resize(img, self.TARGET_SIZE)\n",
        "    \n",
        "    def detect_edges(self, img_thresh):\n",
        "        return cv2.Canny(\n",
        "            img_thresh,\n",
        "            self.CANNY_THRESHOLD_LOW,\n",
        "            self.CANNY_THRESHOLD_HIGH\n",
        "        )\n",
        "    \n",
        "    def dilate_edges(self, canny_image):\n",
        "        kernel = np.ones(self.DILATION_KERNEL_SIZE, np.uint8)\n",
        "        return cv2.dilate(canny_image, kernel, iterations=self.DILATION_ITERATIONS)\n",
        "    \n",
        "    def find_plate_contours(self, dilated_image):\n",
        "        contours, _ = cv2.findContours(\n",
        "            dilated_image,\n",
        "            cv2.RETR_TREE,\n",
        "            cv2.CHAIN_APPROX_SIMPLE\n",
        "        )\n",
        "        \n",
        "        contours = sorted(contours, key=cv2.contourArea, reverse=True)[:self.MAX_CONTOURS]\n",
        "        \n",
        "        plate_contours = []\n",
        "        for contour in contours:\n",
        "            peri = cv2.arcLength(contour, True)\n",
        "            approx = cv2.approxPolyDP(\n",
        "                contour,\n",
        "                self.APPROX_POLY_EPSILON_FACTOR * peri,\n",
        "                True\n",
        "            )\n",
        "            \n",
        "            if len(approx) == 4:\n",
        "                plate_contours.append(approx)\n",
        "        \n",
        "        return plate_contours\n",
        "\n",
        "preprocessor = ImagePreprocessor()\n",
        "detector = PlateDetector()\n",
        "\n",
        "print(\"‚úÖ Modules initialized successfully!\")\n",
        "print(f\"üìê Target size: {detector.TARGET_SIZE}\")\n",
        "print(f\"üî≤ Gaussian kernel size: {preprocessor.GAUSSIAN_SMOOTH_FILTER_SIZE}\")\n",
        "print(f\"üìä Adaptive threshold block size: {preprocessor.ADAPTIVE_THRESH_BLOCK_SIZE}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load Image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Upload ·∫£nh (Google Colab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "print(\"üì§ Vui l√≤ng ch·ªçn file ·∫£nh ƒë·ªÉ upload...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "image_filename = list(uploaded.keys())[0]\n",
        "image_bytes = uploaded[image_filename]\n",
        "image_pil = Image.open(BytesIO(image_bytes))\n",
        "img_original = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "print(f\"‚úÖ ƒê√£ upload ·∫£nh: {image_filename}\")\n",
        "print(f\"üìê K√≠ch th∆∞·ªõc: {img_original.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load ·∫£nh t·ª´ file (T√πy ch·ªçn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'img_original' not in locals() or img_original is None:\n",
        "    possible_paths = [\n",
        "        \"/content/data/test_images/1.jpg\",\n",
        "        \"/content/Image-Processing/data/test_images/1.jpg\",\n",
        "        \"1.jpg\",\n",
        "        \"test_image.jpg\"\n",
        "    ]\n",
        "    \n",
        "    img_original = None\n",
        "    for path in possible_paths:\n",
        "        img_original = cv2.imread(path)\n",
        "        if img_original is not None:\n",
        "            print(f\"‚úÖ ƒê√£ load ·∫£nh t·ª´: {path}\")\n",
        "            break\n",
        "    \n",
        "    if img_original is None:\n",
        "        print(\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y ·∫£nh. Vui l√≤ng upload ·∫£nh ·ªü cell tr∆∞·ªõc.\")\n",
        "        raise FileNotFoundError(\"Kh√¥ng t√¨m th·∫•y ·∫£nh ƒë·ªÉ x·ª≠ l√Ω.\")\n",
        "\n",
        "img_original_rgb = cv2.cvtColor(img_original, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "print(f\"üìê K√≠ch th∆∞·ªõc: {img_original.shape}\")\n",
        "print(f\"üìä Dtype: {img_original.dtype}\")\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(img_original_rgb)\n",
        "plt.title(\"·∫¢nh g·ªëc (Original Image)\", fontsize=16, fontweight='bold')\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. B∆∞·ªõc 1: Resize ·∫£nh v·ªÅ k√≠ch th∆∞·ªõc chu·∫©n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img_resized = detector.resize_image(img_original)\n",
        "img_resized_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "print(f\"üìê K√≠ch th∆∞·ªõc sau resize: {img_resized.shape}\")\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(img_resized_rgb)\n",
        "plt.title(f\"B∆∞·ªõc 1: Resize v·ªÅ k√≠ch th∆∞·ªõc {detector.TARGET_SIZE}\", fontsize=16, fontweight='bold')\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. B∆∞·ªõc 2: Chuy·ªÉn ƒë·ªïi sang Grayscale (HSV Value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img_grayscale = preprocessor.extract_value(img_resized)\n",
        "\n",
        "print(f\"üìê K√≠ch th∆∞·ªõc: {img_grayscale.shape}\")\n",
        "print(f\"üìä Min: {img_grayscale.min()}, Max: {img_grayscale.max()}\")\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(img_grayscale, cmap='gray')\n",
        "plt.title(\"B∆∞·ªõc 2: Chuy·ªÉn ƒë·ªïi sang Grayscale (HSV Value channel)\", fontsize=16, fontweight='bold')\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. B∆∞·ªõc 3: TƒÉng ƒë·ªô t∆∞∆°ng ph·∫£n (Top Hat + Black Hat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img_contrast = preprocessor.maximize_contrast(img_grayscale)\n",
        "\n",
        "print(f\"üìê K√≠ch th∆∞·ªõc: {img_contrast.shape}\")\n",
        "print(f\"üìä Min: {img_contrast.min()}, Max: {img_contrast.max()}\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "axes[0].imshow(img_grayscale, cmap='gray')\n",
        "axes[0].set_title(\"Tr∆∞·ªõc khi tƒÉng t∆∞∆°ng ph·∫£n\", fontsize=14, fontweight='bold')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(img_contrast, cmap='gray')\n",
        "axes[1].set_title(\"B∆∞·ªõc 3: Sau khi tƒÉng t∆∞∆°ng ph·∫£n (Top Hat + Black Hat)\", fontsize=14, fontweight='bold')\n",
        "axes[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. B∆∞·ªõc 4: L√†m m·ªãn ·∫£nh (Gaussian Blur)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img_blurred = cv2.GaussianBlur(\n",
        "    img_contrast, \n",
        "    preprocessor.GAUSSIAN_SMOOTH_FILTER_SIZE, \n",
        "    0\n",
        ")\n",
        "\n",
        "print(f\"üìê K√≠ch th∆∞·ªõc: {img_blurred.shape}\")\n",
        "print(f\"üî≤ Kernel size: {preprocessor.GAUSSIAN_SMOOTH_FILTER_SIZE}\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "axes[0].imshow(img_contrast, cmap='gray')\n",
        "axes[0].set_title(\"Tr∆∞·ªõc khi blur\", fontsize=14, fontweight='bold')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(img_blurred, cmap='gray')\n",
        "axes[1].set_title(f\"B∆∞·ªõc 4: Sau khi blur (Gaussian {preprocessor.GAUSSIAN_SMOOTH_FILTER_SIZE})\", fontsize=14, fontweight='bold')\n",
        "axes[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. B∆∞·ªõc 5: Nh·ªã ph√¢n h√≥a (Adaptive Threshold)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img_thresh = cv2.adaptiveThreshold(\n",
        "    img_blurred,\n",
        "    255.0,\n",
        "    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "    cv2.THRESH_BINARY_INV,\n",
        "    preprocessor.ADAPTIVE_THRESH_BLOCK_SIZE,\n",
        "    preprocessor.ADAPTIVE_THRESH_WEIGHT\n",
        ")\n",
        "\n",
        "print(f\"üìê K√≠ch th∆∞·ªõc: {img_thresh.shape}\")\n",
        "print(f\"üî≤ Block size: {preprocessor.ADAPTIVE_THRESH_BLOCK_SIZE}\")\n",
        "print(f\"‚öñÔ∏è Weight: {preprocessor.ADAPTIVE_THRESH_WEIGHT}\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "axes[0].imshow(img_blurred, cmap='gray')\n",
        "axes[0].set_title(\"Tr∆∞·ªõc khi nh·ªã ph√¢n h√≥a\", fontsize=14, fontweight='bold')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(img_thresh, cmap='gray')\n",
        "axes[1].set_title(f\"B∆∞·ªõc 5: Nh·ªã ph√¢n h√≥a (Adaptive Threshold, block={preprocessor.ADAPTIVE_THRESH_BLOCK_SIZE})\", fontsize=14, fontweight='bold')\n",
        "axes[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. B∆∞·ªõc 6: Ph√°t hi·ªán c·∫°nh (Canny Edge Detection)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img_canny = detector.detect_edges(img_thresh)\n",
        "\n",
        "print(f\"üìê K√≠ch th∆∞·ªõc: {img_canny.shape}\")\n",
        "print(f\"üîç Canny thresholds: Low={detector.CANNY_THRESHOLD_LOW}, High={detector.CANNY_THRESHOLD_HIGH}\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "axes[0].imshow(img_thresh, cmap='gray')\n",
        "axes[0].set_title(\"·∫¢nh nh·ªã ph√¢n\", fontsize=14, fontweight='bold')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(img_canny, cmap='gray')\n",
        "axes[1].set_title(f\"B∆∞·ªõc 6: Ph√°t hi·ªán c·∫°nh (Canny Edge, {detector.CANNY_THRESHOLD_LOW}-{detector.CANNY_THRESHOLD_HIGH})\", fontsize=14, fontweight='bold')\n",
        "axes[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. B∆∞·ªõc 7: Dilation (N·ªëi c√°c c·∫°nh b·ªã ƒë·ª©t ƒëo·∫°n)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img_dilated = detector.dilate_edges(img_canny)\n",
        "\n",
        "print(f\"üìê K√≠ch th∆∞·ªõc: {img_dilated.shape}\")\n",
        "print(f\"üî≤ Kernel size: {detector.DILATION_KERNEL_SIZE}\")\n",
        "print(f\"üîÑ Iterations: {detector.DILATION_ITERATIONS}\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "axes[0].imshow(img_canny, cmap='gray')\n",
        "axes[0].set_title(\"Tr∆∞·ªõc khi dilation\", fontsize=14, fontweight='bold')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(img_dilated, cmap='gray')\n",
        "axes[1].set_title(f\"B∆∞·ªõc 7: Sau khi dilation (kernel={detector.DILATION_KERNEL_SIZE}, iter={detector.DILATION_ITERATIONS})\", fontsize=14, fontweight='bold')\n",
        "axes[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. B∆∞·ªõc 8: T√¨m contour v√† ph√°t hi·ªán bi·ªÉn s·ªë\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plate_contours = detector.find_plate_contours(img_dilated)\n",
        "\n",
        "print(f\"üîç S·ªë l∆∞·ª£ng contour ph√°t hi·ªán ƒë∆∞·ª£c: {len(plate_contours)}\")\n",
        "\n",
        "img_with_contours = img_resized.copy()\n",
        "for contour in plate_contours:\n",
        "    cv2.drawContours(img_with_contours, [contour], -1, (0, 255, 0), 3)\n",
        "\n",
        "img_with_contours_rgb = cv2.cvtColor(img_with_contours, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "axes[0].imshow(img_resized_rgb)\n",
        "axes[0].set_title(\"·∫¢nh g·ªëc\", fontsize=14, fontweight='bold')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(img_with_contours_rgb)\n",
        "axes[1].set_title(f\"B∆∞·ªõc 8: Ph√°t hi·ªán bi·ªÉn s·ªë ({len(plate_contours)} bi·ªÉn s·ªë)\", fontsize=14, fontweight='bold')\n",
        "axes[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "if len(plate_contours) > 0:\n",
        "    print(\"\\nüìã Chi ti·∫øt c√°c contour ph√°t hi·ªán ƒë∆∞·ª£c:\")\n",
        "    for i, contour in enumerate(plate_contours):\n",
        "        area = cv2.contourArea(contour)\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        print(f\"  Contour {i+1}: Area={area:.0f}, Bounding box=({x}, {y}, {w}, {h})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. T·ªïng k·∫øt: Hi·ªÉn th·ªã t·∫•t c·∫£ c√°c b∆∞·ªõc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "axes[0].imshow(img_resized_rgb)\n",
        "axes[0].set_title(\"1. ·∫¢nh g·ªëc (Resized)\", fontsize=12, fontweight='bold')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(img_grayscale, cmap='gray')\n",
        "axes[1].set_title(\"2. Grayscale (HSV Value)\", fontsize=12, fontweight='bold')\n",
        "axes[1].axis('off')\n",
        "\n",
        "axes[2].imshow(img_contrast, cmap='gray')\n",
        "axes[2].set_title(\"3. TƒÉng t∆∞∆°ng ph·∫£n\", fontsize=12, fontweight='bold')\n",
        "axes[2].axis('off')\n",
        "\n",
        "axes[3].imshow(img_blurred, cmap='gray')\n",
        "axes[3].set_title(\"4. Gaussian Blur\", fontsize=12, fontweight='bold')\n",
        "axes[3].axis('off')\n",
        "\n",
        "axes[4].imshow(img_thresh, cmap='gray')\n",
        "axes[4].set_title(\"5. Adaptive Threshold\", fontsize=12, fontweight='bold')\n",
        "axes[4].axis('off')\n",
        "\n",
        "axes[5].imshow(img_canny, cmap='gray')\n",
        "axes[5].set_title(\"6. Canny Edge\", fontsize=12, fontweight='bold')\n",
        "axes[5].axis('off')\n",
        "\n",
        "axes[6].imshow(img_dilated, cmap='gray')\n",
        "axes[6].set_title(\"7. Dilation\", fontsize=12, fontweight='bold')\n",
        "axes[6].axis('off')\n",
        "\n",
        "axes[7].imshow(img_with_contours_rgb)\n",
        "axes[7].set_title(f\"8. Ph√°t hi·ªán bi·ªÉn s·ªë ({len(plate_contours)})\", fontsize=12, fontweight='bold')\n",
        "axes[7].axis('off')\n",
        "\n",
        "plt.suptitle(\"T·ªïng h·ª£p c√°c b∆∞·ªõc x·ª≠ l√Ω ·∫£nh\", fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Th√¥ng tin c√°c tham s·ªë s·ª≠ d·ª•ng\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"TH√îNG TIN C√ÅC THAM S·ªê X·ª¨ L√ù ·∫¢NH\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\n1. K√≠ch th∆∞·ªõc ·∫£nh chu·∫©n: {detector.TARGET_SIZE}\")\n",
        "print(f\"\\n2. Preprocessing:\")\n",
        "print(f\"   - Gaussian kernel size: {preprocessor.GAUSSIAN_SMOOTH_FILTER_SIZE}\")\n",
        "print(f\"   - Adaptive threshold block size: {preprocessor.ADAPTIVE_THRESH_BLOCK_SIZE}\")\n",
        "print(f\"   - Adaptive threshold weight: {preprocessor.ADAPTIVE_THRESH_WEIGHT}\")\n",
        "print(f\"   - Morphology iterations: {preprocessor.MORPHOLOGY_ITERATIONS}\")\n",
        "print(f\"   - Morphology kernel size: {preprocessor.MORPHOLOGY_KERNEL_SIZE}\")\n",
        "print(f\"\\n3. Edge Detection:\")\n",
        "print(f\"   - Canny threshold low: {detector.CANNY_THRESHOLD_LOW}\")\n",
        "print(f\"   - Canny threshold high: {detector.CANNY_THRESHOLD_HIGH}\")\n",
        "print(f\"   - Dilation kernel size: {detector.DILATION_KERNEL_SIZE}\")\n",
        "print(f\"   - Dilation iterations: {detector.DILATION_ITERATIONS}\")\n",
        "print(f\"   - Max contours: {detector.MAX_CONTOURS}\")\n",
        "print(f\"   - Approx poly epsilon factor: {detector.APPROX_POLY_EPSILON_FACTOR}\")\n",
        "print(\"=\" * 60)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
